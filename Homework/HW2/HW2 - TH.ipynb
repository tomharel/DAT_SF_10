{
 "metadata": {
  "name": "",
  "signature": "sha256:aeaafe0eedaf9b29ae1e676ea96b32ba8000325e39aab6563bb2b68cd9f85593"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# QUESTION 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# Load Iris data and create column headers\n",
      "iris = pd.read_csv('iris.csv', header=None, nrows = 150)\n",
      "iris.columns = ('c1','c2','c3','c4','class')\n",
      "print iris.info()\n",
      "\n",
      "# Split dataset into Data (X) and Class (y)\n",
      "X = iris.as_matrix(['c1', 'c2', 'c3', 'c4']).astype(float)\n",
      "y = iris.as_matrix(['class']).astype(str)\n",
      "y = np.ravel(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 150 entries, 0 to 149\n",
        "Data columns (total 5 columns):\n",
        "c1       150 non-null float64\n",
        "c2       150 non-null float64\n",
        "c3       150 non-null float64\n",
        "c4       150 non-null float64\n",
        "class    150 non-null object\n",
        "dtypes: float64(4), object(1)None\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "# KNN\n",
      "t = 0.2\n",
      "n = 3\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = t, random_state = 0)\n",
      "knn = KNeighborsClassifier(n).fit(X_train, y_train)\n",
      "knn.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# QUESTION 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "# Define Cross Validation Function\n",
      "def knn_cross_validate(X, y, k_fold, neighbors = 3):\n",
      "\n",
      "    # Sets of Training and Testing\n",
      "    num_elements = len(X)\n",
      "    k_fold_indices = KFold(num_elements, n_folds= k_fold, indices=True, shuffle=True, random_state=0)\n",
      "    k_score_total = 0\n",
      "    \n",
      "    # for each training and testing slices run the classifier, and score the results\n",
      "    for train_slice, test_slice in k_fold_indices :\n",
      "\n",
      "        model = KNeighborsClassifier(neighbors).fit(X[ train_slice  ], y[ train_slice  ])\n",
      "\n",
      "        k_score = model.score(X[ test_slice ], y[ test_slice ])\n",
      "\n",
      "        k_score_total += k_score\n",
      "\n",
      "    # return the average accuracy\n",
      "    return k_score_total/k_fold\n",
      "\n",
      "\n",
      "# Implementation for 3 neighbors, testing wth 5 folds.\n",
      "knn_cross_validate(X, y, 5, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 104,
       "text": [
        "0.95333333333333337"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# QUESTION 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from operator import itemgetter\n",
      "\n",
      "# Loop over possible values of K (2-149 inclusive) and find the K for which average accuracy is maximized.\n",
      "tuple_list = []\n",
      "accuracy_list = []\n",
      "K_list = []\n",
      "for z in range(2,len(X)+1):\n",
      "    accu = knn_cross_validate(X, y, 5, z)    \n",
      "    tuple_list.append((z, accu))\n",
      "    accuracy_list.append(accu)\n",
      "    K_list.append(z)\n",
      "    \n",
      "# Get maximum average accuracy\n",
      "max_avg_accuracy_tuple = max(tuple_list, key=itemgetter(1))\n",
      "\n",
      "# Report optimal K\n",
      "print \"Using 5 folds, the optimal K = \" + str(max_avg_accuracy_tuple[0]) + \\\n",
      "\" @ Average Accuracy = \" + str(max_avg_accuracy_tuple[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using 5 folds, the optimal K = 11 @ Average Accuracy = 0.966666666667\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# QUESTION 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "from matplotlib.ticker import FormatStrFormatter\n",
      "\n",
      "# Plotting the entire range of K, and the interesting part where K = [60,90]\n",
      "fig = plt.figure(0)\n",
      "ax1 = fig.add_subplot(1,2,1)\n",
      "ax2 = fig.add_subplot(1,2,2)\n",
      "fig.suptitle('Classifier Accuracy v. K', fontsize=28)\n",
      "majorFormatter = FormatStrFormatter('%1.1f')\n",
      "\n",
      "for ax in plt.gcf().axes:\n",
      "    ax.yaxis.set_major_formatter(majorFormatter)    \n",
      "    \n",
      "    for ticklabel in ax.get_xticklabels() + ax1.get_yticklabels():\n",
      "        ticklabel.set_fontsize(10)\n",
      "\n",
      "ax1.scatter(K_list, accuracy_list)\n",
      "ax1.set_xlabel('K', fontsize=14)\n",
      "ax1.set_ylabel('Average Accuracy', fontsize=14)\n",
      "\n",
      "ax2.scatter(K_list[58:89], accuracy_list[58:89])\n",
      "ax2.set_xlabel('K', fontsize=14)\n",
      "ax2.set_ylabel('Average Accuracy', fontsize=14)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Explanation:\n",
      "# In the left figure, we see the full range of average accuracy v. K. That is, we see how our accuracy responds to changes in K.\n",
      "# In the right figure, we see part of the first plot, where K = [60, 90]. I think that this part of the plot is the\n",
      "# most interesting, because we can see how detrimental it could be to get the K wrong. We see that using K~60 seems to be\n",
      "# good results (~90% -- I am aware that if K < 60 we can do even better), and using K~90 we get very bad results (~50%). \n",
      "# This means we must choose our K wisely when applying a KNN predictive model, as choosing a \"bad\" K\n",
      "# can cause very bad classification accuracy."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OPTIONAL BONUS QUESTION"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_range = [2,3,5,6,10,15]\n",
      "interesting_results = []\n",
      "for i in interesting_range:\n",
      "#     interesting_results.append((i,knn_cross_validate(X, y, i, 8)))\n",
      "    print \"Using \" + str(i) + \" Folds we get accuracy = \" + str(knn_cross_validate(X, y, i, 8))\n",
      "# print interesting_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using 2 Folds we get accuracy = 0.96\n",
        "Using 3 Folds we get accuracy = 0.96\n",
        "Using 5 Folds we get accuracy = 0.96\n",
        "Using 6 Folds we get accuracy = 0.96\n",
        "Using 10 Folds we get accuracy = 0.953333333333\n",
        "Using 15 Folds we get accuracy = 0.96"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# It seems the accuracy doesn't vary so much with the number of folds used.\n",
      "# I don't think there's an optimal number of folds to use, because it makes no sense.\n",
      "# The only one that stands out is 10 folds, but I see no reason what it's result is a) more valid, b) changes anything."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    }
   ],
   "metadata": {}
  }
 ]
}