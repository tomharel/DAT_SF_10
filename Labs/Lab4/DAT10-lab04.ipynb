{
 "metadata": {
  "name": "",
  "signature": "sha256:989c2e2ab69f16e3851d5ea86e2d90beb07b5ae010952a026f89b87994f8c3d9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# GA Data Science 10 (DAT10) - Lab4\n",
      "\n",
      "### KNN, Matplotlib\n",
      "\n",
      "Craig Sakuma"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Last Time:\n",
      "\n",
      "- #### Numpy\n",
      "- #### Pandas\n",
      "- #### Kimono Labs API\n",
      "\n",
      "#### Questions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Agenda\n",
      "\n",
      "1. Matplotlib\n",
      "2. KNN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1. Matplotlib"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# where do we find Machine Learning algorithms in python?\n",
      "\n",
      "# sklearn\n",
      "# http://scikit-learn.org/stable/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make things simple, load a default dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from the datasets load the iris data into a variable called iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = datasets.load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What does the iris data set look like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(iris)\n",
      "# iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "sklearn.datasets.base.Bunch"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['target_names', 'data', 'target', 'DESCR', 'feature_names']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print iris['DESCR']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iris Plants Database\n",
        "\n",
        "Notes\n",
        "-----\n",
        "Data Set Characteristics:\n",
        "    :Number of Instances: 150 (50 in each of three classes)\n",
        "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
        "    :Attribute Information:\n",
        "        - sepal length in cm\n",
        "        - sepal width in cm\n",
        "        - petal length in cm\n",
        "        - petal width in cm\n",
        "        - class:\n",
        "                - Iris-Setosa\n",
        "                - Iris-Versicolour\n",
        "                - Iris-Virginica\n",
        "    :Summary Statistics:\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "                    Min  Max   Mean    SD   Class Correlation\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
        "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
        "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
        "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "    :Missing Attribute Values: None\n",
        "    :Class Distribution: 33.3% for each of 3 classes.\n",
        "    :Creator: R.A. Fisher\n",
        "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
        "    :Date: July, 1988\n",
        "\n",
        "This is a copy of UCI ML iris datasets.\n",
        "http://archive.ics.uci.edu/ml/datasets/Iris\n",
        "\n",
        "The famous Iris database, first used by Sir R.A Fisher\n",
        "\n",
        "This is perhaps the best known database to be found in the\n",
        "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
        "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
        "data set contains 3 classes of 50 instances each, where each class refers to a\n",
        "type of iris plant.  One class is linearly separable from the other 2; the\n",
        "latter are NOT linearly separable from each other.\n",
        "\n",
        "References\n",
        "----------\n",
        "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
        "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
        "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
        "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
        "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
        "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
        "     Structure and Classification Rule for Recognition in Partially Exposed\n",
        "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
        "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
        "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
        "     on Information Theory, May 1972, 431-433.\n",
        "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
        "     conceptual clustering system finds 3 classes in the data.\n",
        "   - Many, many more ...\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lets display that data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "from matplotlib.ticker import FormatStrFormatter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the data with load_iris from sklearn\n",
      "X = iris['data']\n",
      "Names = iris['feature_names']\n",
      "y = iris['target']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Seeing X, y, Names\n",
      "# ..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate the top-level figure for this plotting exercise\n",
      "fig = plt.figure(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate our six subplots. Note that context will be set to the last one by default.\n",
      "ax1 = fig.add_subplot(2,3,1)\n",
      "ax2 = fig.add_subplot(2,3,2)\n",
      "ax3 = fig.add_subplot(2,3,3)\n",
      "ax4 = fig.add_subplot(2,3,4)\n",
      "ax5 = fig.add_subplot(2,3,5)\n",
      "ax6 = fig.add_subplot(2,3,6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Title our figure. This is a different command than titling an individual subplot.\n",
      "fig.suptitle('Subplots demo with Iris Data', fontsize=14)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "<matplotlib.text.Text at 0x146f4470>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets the number of decimal places in our y-axis tick labels\n",
      "majorFormatter = FormatStrFormatter('%1.1f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "majorFormatter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "<matplotlib.ticker.FormatStrFormatter at 0x146f4710>"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loop through our subplots and set font sizes\n",
      "# HINT: plt.gcf().axes gets all the axes for our current figure\n",
      "all_axes = plt.gcf().axes\n",
      "for ax in all_axes:\n",
      "    ax.yaxis.set_major_formatter(majorFormatter)\n",
      "    for ticklabel in ax.get_xticklabels() + ax.get_yticklabels():\n",
      "        ticklabel.set_fontsize(6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format first subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    # We plot each class on its own to get different colored markers\n",
      "    ax1.scatter(X[y == t,0],\n",
      "                X[y == t,1],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax1.set_xlabel(Names[0], fontsize=8)\n",
      "    ax1.set_ylabel(Names[1], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Zip Function Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# zip([1,2,3],['a','b','c'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format second subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax2.scatter(X[y == t,0],\n",
      "                X[y == t,2],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax2.set_xlabel(Names[0], fontsize=8)\n",
      "    ax2.set_ylabel(Names[2], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format third subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax3.scatter(X[y == t,0],\n",
      "                X[y == t,3],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax3.set_xlabel(Names[0], fontsize=8)\n",
      "    ax3.set_ylabel(Names[3], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format fourth subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax4.scatter(X[y == t,1],\n",
      "                X[y == t,2],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax4.set_xlabel(Names[1], fontsize=8)\n",
      "    ax4.set_ylabel(Names[2], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format fifth subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax5.scatter(X[y == t,1],\n",
      "                X[y == t,3],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax5.set_xlabel(Names[1], fontsize=8)\n",
      "    ax5.set_ylabel(Names[3], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format sixth subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax6.scatter(X[y == t,2],\n",
      "                X[y == t,3],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax6.set_xlabel(Names[2], fontsize=8)\n",
      "    ax6.set_ylabel(Names[3], fontsize=8)\n",
      "\n",
      "# Save our figure with subplots as one file\n",
      "# plt.savefig('iris_plot_combined.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. KNN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's re-assign the data to standard named variables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = iris.data\n",
      "y = iris.target\n",
      "Names = iris.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the data into training set and test set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# is there a function to do that in sklearn?\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train KNN classifier defined function on the train data\n",
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn = KNeighborsClassifier(3).fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise #1\n",
      "### How does the model perform when you increase the number of neighbors?  \n",
      "\n",
      "###How much do the scores vary each time you shuffle and split?\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(10):\n",
      "    myknn2 = KNeighborsClassifier(i+1).fit(X_train,y_train)\n",
      "    print \"Using \" + str(i+1) + \" neighbors I get: \" + str(round(myknn2.score(X_test, y_test),4)*100) + \"%\"\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using 1 neighbors I get: 100.0%\n",
        "\n",
        "Using 2 neighbors I get: 96.67%\n",
        "\n",
        "Using 3 neighbors I get: 96.67%\n",
        "\n",
        "Using 4 neighbors I get: 100.0%\n",
        "\n",
        "Using 5 neighbors I get: 96.67%\n",
        "\n",
        "Using 6 neighbors I get: 100.0%\n",
        "\n",
        "Using 7 neighbors I get: 100.0%\n",
        "\n",
        "Using 8 neighbors I get: 100.0%\n",
        "\n",
        "Using 9 neighbors I get: 100.0%\n",
        "\n",
        "Using 10 neighbors I get: 100.0%\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(9):\n",
      "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20)\n",
      "    myknn2 = KNeighborsClassifier(i+1).fit(X_train,y_train)\n",
      "    print \"Using \" + str(i+1) + \" neighbors I get: \" + str(round(myknn2.score(X_test, y_test),4)*100) + \"%\"\n",
      "    print\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using 1 neighbors I get: 93.33%\n",
        "\n",
        "Using 2 neighbors I get: 90.0%\n",
        "\n",
        "Using 3 neighbors I get: 93.33%\n",
        "\n",
        "Using 4 neighbors I get: 100.0%\n",
        "\n",
        "Using 5 neighbors I get: 100.0%\n",
        "\n",
        "Using 6 neighbors I get: 100.0%\n",
        "\n",
        "Using 7 neighbors I get: 100.0%\n",
        "\n",
        "Using 8 neighbors I get: 100.0%\n",
        "\n",
        "Using 9 neighbors I get: 100.0%\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cross Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The Simplest way to do Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples = len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
      "\n",
      "n_samples = len(y)\n",
      "knn = KNeighborsClassifier(3)\n",
      "cv = ShuffleSplit(n_samples, n_iter=10, test_size=0.3, random_state=0)\n",
      "\n",
      "test_scores = cross_val_score(knn, X, y, cv=cv)\n",
      "print test_scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.962222222222\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise #2\n",
      "### Calculate the cross-validation score for test_sizes of .1 and .9\n",
      "### How does the model perform at the different test sizes?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(1,10):\n",
      "    j = float(i) / 10\n",
      "    cv = ShuffleSplit(n_samples, n_iter=10, test_size=j, random_state=0)\n",
      "    test_scores = cross_val_score(knn, X, y, cv=cv)\n",
      "    print \"Using \" + str(int(j*100)) + \"%: \" + str(round(test_scores.mean()*100,2)) + \"%\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using 10%: 97.33%\n",
        "Using 20%: 96.67%\n",
        "Using 30%: 96.22%\n",
        "Using 40%: 95.83%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Using 50%: 95.73%\n",
        "Using 60%: 95.0%\n",
        "Using 70%: 94.19%\n",
        "Using 80%: 94.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Using 90%: 90.0%\n"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### KFolds Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generic cross validation function\n",
      "def cross_validate(X, y, classifier, k_fold) :\n",
      "\n",
      "    # derive a set of (random) training and testing indices\n",
      "    k_fold_indices = KFold( len(X), n_folds=k_fold,\n",
      "                           indices=True, shuffle=True,\n",
      "                           random_state=0)\n",
      "\n",
      "    k_score_total = 0\n",
      "    # for each training and testing slices run the classifier, and score the results\n",
      "    for train_slice, test_slice in k_fold_indices :\n",
      "\n",
      "        model = classifier(X[ train_slice  ],\n",
      "                         y[ train_slice  ])\n",
      "\n",
      "        k_score = model.score(X[ test_slice ],\n",
      "                              y[ test_slice ])\n",
      "\n",
      "        k_score_total += k_score\n",
      "\n",
      "    # return the average accuracy\n",
      "    return k_score_total/k_fold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X, y, KNeighborsClassifier(3).fit, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "0.95999999999999996"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Enumerate Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x,y in enumerate(['a','b','c']):\n",
      "    print x, \"   \",y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0     a\n",
        "1     b\n",
        "2     c\n"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Another way to do Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import ShuffleSplit\n",
      "\n",
      "cv = ShuffleSplit(n_samples, n_iter=3, test_size=0.1,\n",
      "    random_state=0)\n",
      "\n",
      "for cv_index, (train, test) in enumerate(cv):\n",
      "    print(\"# Cross Validation Iteration #%d\" % cv_index)\n",
      "    print(\"train indices: {0}...\".format(train[:10]))\n",
      "    print(\"test indices: {0}...\".format(test[:10]))\n",
      "    \n",
      "    myknn = KNeighborsClassifier(3).fit(X[train], y[train])\n",
      "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
      "        myknn.score(X[train], y[train]), myknn.score(X[test], y[test])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Cross Validation Iteration #0\n",
        "train indices: [ 37  78  90  45  16 121  66  24   8 126]...\n",
        "test indices: [114  62  33 107   7 100  40  86  76  71]...\n",
        "train score: 0.956, test score: 1.000\n",
        "\n",
        "# Cross Validation Iteration #1\n",
        "train indices: [148   6  65  47  68  60  15 124  58 142]...\n",
        "test indices: [ 92 141 130 119  48 143 122  63  26  64]...\n",
        "train score: 0.963, test score: 0.933\n",
        "\n",
        "# Cross Validation Iteration #2\n",
        "train indices: [ 62  76  69  46 129   1  10   3  95  21]...\n",
        "test indices: [ 85 137  77 108 122 104 121  12  31  96]...\n",
        "train score: 0.963, test score: 0.933\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 144
    }
   ],
   "metadata": {}
  }
 ]
}